step: 0, state: ((5, 0), (4, 1)), Q: [-345.82090878 -347.34771943 -347.34771815 -335.70476858], actions: 4, next state: ((5, 1), (4, 1)), reward: -14
step: 1, state: ((5, 1), (4, 1)), Q: [-324.9543117  -335.70425525 -347.34770814 -347.34379254], actions: 1, next state: ((4, 1), (3, 1)), reward: -15
step: 2, state: ((4, 1), (3, 1)), Q: [-313.08516333 -337.70475729 -337.66919646 -337.70024197], actions: 1, next state: ((3, 1), (2, 1)), reward: -16
step: 3, state: ((3, 1), (2, 1)), Q: [-300.08602357 -326.95389871 -326.89509988 -326.93727968], actions: 1, next state: ((2, 1), (1, 1)), reward: -17
step: 4, state: ((2, 1), (1, 1)), Q: [-300.08602299 -314.50673819 -285.94547835 -315.07352809], actions: 3, next state: ((2, 0), (1, 1)), reward: -18
step: 5, state: ((2, 0), (1, 1)), Q: [-270.65199833 -302.08590725 -285.94456104 -300.08565101], actions: 1, next state: ((1, 0), (1, 1)), reward: -17
step: 6, state: ((1, 0), (1, 1)), Q: [-285.94545098 -285.94036923 -270.65110782 -256.21413973], actions: 4, next state: ((1, 1), (1, 2)), reward: -16
step: 7, state: ((1, 1), (1, 2)), Q: [-270.65184725 -270.65198058 -270.65176395 -242.64054518], actions: 4, next state: ((1, 2), (1, 3)), reward: -15
step: 8, state: ((1, 2), (1, 3)), Q: [-256.19878722 -256.21242315 -256.21280142 -229.93994463], actions: 4, next state: ((1, 3), (1, 4)), reward: -14
step: 9, state: ((1, 3), (1, 4)), Q: [ -226.99011762 -1014.99612808  -242.62897249  -218.12115619], actions: 4, next state: ((1, 4), (1, 5)), reward: -13
step: 10, state: ((1, 4), (1, 5)), Q: [ -207.19308706  -229.92749125  -229.93974628 -1011.99975872], actions: 1, next state: ((0, 4), (1, 5)), reward: -14
step: 11, state: ((0, 4), (1, 5)), Q: [-207.19297014 -218.11890679 -220.12111954 -195.14453238], actions: 4, next state: ((0, 5), (1, 5)), reward: -13
step: 12, state: ((0, 5), (1, 5)), Q: [ -195.1445311   -183.98437615  -207.19294256 -1013.99993956], actions: 2, next state: ((1, 5), (2, 5)), reward: -12
step: 13, state: ((1, 5), (2, 5)), Q: [ -194.98546729  -173.72159207  -194.97536649 -1012.99903393], actions: 2, next state: ((2, 5), (3, 5)), reward: -11
step: 14, state: ((2, 5), (3, 5)), Q: [ -183.98015065  -164.36524451  -183.9663306  -1011.99613953], actions: 2, next state: ((3, 5), (4, 5)), reward: -10
step: 15, state: ((3, 5), (4, 5)), Q: [ -173.72153857  -164.36517823  -155.92448941 -1010.99903584], actions: 3, next state: ((3, 4), (4, 5)), reward: -11
step: 16, state: ((3, 4), (4, 5)), Q: [ -166.36490735  -146.38837314 -1011.99903488  -164.36519486], actions: 2, next state: ((4, 4), (4, 5)), reward: -10
step: 17, state: ((4, 4), (4, 5)), Q: [ -155.92448802  -155.91700842 -1010.99993974  -137.76603347], actions: 4, next state: ((4, 5), (4, 6)), reward: -9
step: 18, state: ((4, 5), (4, 6)), Q: [-146.38327232 -146.38818044 -146.38832323 -130.06670048], actions: 4, next state: ((4, 6), (4, 7)), reward: -8
step: 19, state: ((4, 6), (4, 7)), Q: [-1008.99993986  -132.89054198  -137.76421021  -123.29969745], actions: 4, next state: ((4, 7), (4, 8)), reward: -7
step: 20, state: ((4, 7), (4, 8)), Q: [ -130.06577134  -117.47444187  -128.65449161 -1005.9995203 ], actions: 2, next state: ((5, 7), (4, 8)), reward: -8
step: 21, state: ((5, 7), (4, 8)), Q: [-123.2996673  -117.47441981 -125.29790529 -110.58024431], actions: 4, next state: ((5, 8), (4, 8)), reward: -7
step: 22, state: ((5, 8), (4, 8)), Q: [ -104.62650941  -110.58024007  -117.47127232 -1007.99999906], actions: 1, next state: ((4, 8), (3, 8)), reward: -8
step: 23, state: ((4, 8), (3, 8)), Q: [ -112.94805241  -112.58008599   -97.60253475 -1008.99951887], actions: 3, next state: ((4, 7), (3, 8)), reward: -9
step: 24, state: ((4, 7), (3, 8)), Q: [ -89.49750985 -106.6118558  -106.60852236 -104.62647405], actions: 1, next state: ((3, 7), (3, 8)), reward: -8
step: 25, state: ((3, 7), (3, 8)), Q: [  -97.60230505   -97.60242683 -1008.99615097   -82.32071702], actions: 4, next state: ((3, 8), (3, 9)), reward: -7
step: 26, state: ((3, 8), (3, 9)), Q: [-89.49732886 -89.49750828 -89.49728692 -76.08153235], actions: 4, next state: ((3, 9), (3, 10)), reward: -6
step: 27, state: ((3, 9), (3, 10)), Q: [-1006.99987996 -1006.99951982   -82.32063951   -70.78942661], actions: 4, next state: ((3, 10), (3, 11)), reward: -5
step: 28, state: ((3, 10), (3, 11)), Q: [  -75.45029558   -66.45396628   -76.07718888 -1003.99976063], actions: 2, next state: ((4, 10), (3, 11)), reward: -6
step: 29, state: ((4, 10), (3, 11)), Q: [  -70.78941185   -72.6326564  -1006.99987996   -61.0646124 ], actions: 4, next state: ((4, 11), (3, 11)), reward: -5
step: 30, state: ((4, 11), (3, 11)), Q: [  -56.63092162   -66.45395149   -66.45330722 -1005.99616241], actions: 1, next state: ((3, 11), (2, 11)), reward: -6
step: 31, state: ((3, 11), (2, 11)), Q: [  -51.14234507   -63.06312452   -63.05509858 -1006.9980793 ], actions: 1, next state: ((2, 11), (1, 11)), reward: -7
step: 32, state: ((2, 11), (1, 11)), Q: [  -51.14234496   -58.61680912   -44.58822734 -1007.99999953], actions: 3, next state: ((2, 10), (1, 11)), reward: -8
step: 33, state: ((2, 10), (1, 11)), Q: [  -36.95780539   -53.13877536 -1008.99996993   -51.14234475], actions: 1, next state: ((1, 10), (1, 11)), reward: -7
step: 34, state: ((1, 10), (1, 11)), Q: [  -44.58752859   -44.54069666 -1007.99998498   -30.26040949], actions: 4, next state: ((1, 11), (1, 12)), reward: -6
step: 35, state: ((1, 11), (1, 12)), Q: [-36.94876094 -36.95665616 -36.95496246 -24.50546413], actions: 4, next state: ((1, 12), (1, 13)), reward: -5
step: 36, state: ((1, 12), (1, 13)), Q: [  -19.70248902 -1005.99616241   -30.22823319   -24.50546409], actions: 1, next state: ((0, 12), (1, 13)), reward: -6
step: 37, state: ((0, 12), (1, 13)), Q: [-19.70189677 -24.50532744 -26.50466392 -13.840898  ], actions: 4, next state: ((0, 13), (1, 13)), reward: -5
step: 38, state: ((0, 13), (1, 13)), Q: [-13.84089427  -8.9302     -19.70247916 -13.840898  ], actions: 2, next state: ((1, 13), (2, 13)), reward: -4
step: 39, state: ((1, 13), (2, 13)), Q: [-13.84073622  -4.98       -13.8401212   -8.93019435], actions: 2, next state: ((2, 13), (3, 13)), reward: -3
step: 40, state: ((2, 13), (3, 13)), Q: [   -8.92844066    -2.         -1003.99997008    -4.97999621], actions: 2, next state: ((3, 13), (4, 13)), reward: -2

rewards: -388
print the historical actions: [[4], [1], [1], [1], [3], [1], [4], [4], [4], [4], [1], [4], [2], [2], [2], [3], [2], [4], [4], [4], [2], [4], [1], [3], [1], [4], [4], [4], [2], [4], [1], [1], [3], [1], [4], [4], [1], [4], [2], [2], [2]]
