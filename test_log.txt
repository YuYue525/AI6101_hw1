step: 0, state: ((5, 0), (4, 1)), Q: [-347.75549828 -347.34767822 -347.34768917 -335.70476858], actions: 4, next state: ((5, 1), (4, 1)), reward: -14
step: 1, state: ((5, 1), (4, 1)), Q: [-324.9543117  -335.70472526 -347.33415639 -347.34769953], actions: 1, next state: ((4, 1), (3, 1)), reward: -15
step: 2, state: ((4, 1), (3, 1)), Q: [-313.08516333 -337.69321581 -331.98291791 -337.70474902], actions: 1, next state: ((3, 1), (2, 1)), reward: -16
step: 3, state: ((3, 1), (2, 1)), Q: [-300.08602357 -326.94624696 -326.94716838 -326.82801496], actions: 1, next state: ((2, 1), (1, 1)), reward: -17
step: 4, state: ((2, 1), (1, 1)), Q: [-300.07871983 -315.06655429 -285.94547835 -314.99940619], actions: 3, next state: ((2, 0), (1, 1)), reward: -18
step: 5, state: ((2, 0), (1, 1)), Q: [-270.65199833 -302.08600442 -285.94546472 -300.08582824], actions: 1, next state: ((1, 0), (1, 1)), reward: -17
step: 6, state: ((1, 0), (1, 1)), Q: [-285.94535732 -285.94546614 -270.65181121 -256.21413973], actions: 4, next state: ((1, 1), (1, 2)), reward: -16
step: 7, state: ((1, 1), (1, 2)), Q: [-270.51695631 -270.65183191 -270.65147686 -242.64054518], actions: 4, next state: ((1, 2), (1, 3)), reward: -15
step: 8, state: ((1, 2), (1, 3)), Q: [-254.35283904 -256.21388587 -256.21205968 -229.93994463], actions: 4, next state: ((1, 3), (1, 4)), reward: -14
step: 9, state: ((1, 3), (1, 4)), Q: [ -231.2989239  -1014.99999244  -242.63997906  -218.12115619], actions: 4, next state: ((1, 4), (1, 5)), reward: -13
step: 10, state: ((1, 4), (1, 5)), Q: [ -207.19308706  -229.93734608  -229.9395738  -1011.99975872], actions: 1, next state: ((0, 4), (1, 5)), reward: -14
step: 11, state: ((0, 4), (1, 5)), Q: [-207.19302442 -218.12100722 -220.12107381 -195.14453238], actions: 4, next state: ((0, 5), (1, 5)), reward: -13
step: 12, state: ((0, 5), (1, 5)), Q: [ -195.14451577  -183.98437615  -207.18738363 -1013.98452759], actions: 2, next state: ((1, 5), (2, 5)), reward: -12
step: 13, state: ((1, 5), (2, 5)), Q: [ -195.14450324  -173.72159207  -195.05162852 -1012.99613571], actions: 2, next state: ((2, 5), (3, 5)), reward: -11
step: 14, state: ((2, 5), (3, 5)), Q: [ -183.98362312  -164.36524451  -183.71059672 -1011.99996984], actions: 2, next state: ((3, 5), (4, 5)), reward: -10
step: 15, state: ((3, 5), (4, 5)), Q: [ -173.71609133  -164.3652445   -155.92448941 -1010.99999623], actions: 3, next state: ((3, 4), (4, 5)), reward: -11
step: 16, state: ((3, 4), (4, 5)), Q: [ -166.35967455  -146.38837314 -1011.99999246  -164.36521128], actions: 2, next state: ((4, 4), (4, 5)), reward: -10
step: 17, state: ((4, 4), (4, 5)), Q: [ -155.92448933  -155.92193244 -1010.99999906  -137.76603347], actions: 4, next state: ((4, 5), (4, 6)), reward: -9
step: 18, state: ((4, 5), (4, 6)), Q: [-146.38205144 -146.38464266 -146.38811722 -130.06670048], actions: 4, next state: ((4, 6), (4, 7)), reward: -8
step: 19, state: ((4, 6), (4, 7)), Q: [-1008.99807549  -131.66787286  -137.76268075  -123.29969745], actions: 4, next state: ((4, 7), (4, 8)), reward: -7
step: 20, state: ((4, 7), (4, 8)), Q: [ -130.06647854  -117.47444187  -130.06667109 -1005.99997002], actions: 2, next state: ((5, 7), (4, 8)), reward: -8
step: 21, state: ((5, 7), (4, 8)), Q: [-123.29969361 -117.47435365 -125.29040313 -110.58024431], actions: 4, next state: ((5, 8), (4, 8)), reward: -7
step: 22, state: ((5, 8), (4, 8)), Q: [ -104.62650941  -110.58019979  -117.47444169 -1007.87695312], actions: 1, next state: ((4, 8), (3, 8)), reward: -8
step: 23, state: ((4, 8), (3, 8)), Q: [ -109.43179009  -112.57977503   -97.60253475 -1008.99903774], actions: 3, next state: ((4, 7), (3, 8)), reward: -9
step: 24, state: ((4, 7), (3, 8)), Q: [ -89.49750985 -106.62469046 -106.62264861 -104.62649624], actions: 1, next state: ((3, 7), (3, 8)), reward: -8
step: 25, state: ((3, 7), (3, 8)), Q: [  -97.60248207   -97.60250808 -1008.99993986   -82.32071702], actions: 4, next state: ((3, 8), (3, 9)), reward: -7
step: 26, state: ((3, 8), (3, 9)), Q: [-89.49748581 -89.45351366 -89.49720362 -76.08153235], actions: 4, next state: ((3, 9), (3, 10)), reward: -6
step: 27, state: ((3, 9), (3, 10)), Q: [-1006.99951982 -1006.9846344    -82.28222798   -70.78942661], actions: 4, next state: ((3, 10), (3, 11)), reward: -5
step: 28, state: ((3, 10), (3, 11)), Q: [  -75.92558936   -66.45396628   -76.0813312  -1003.99234009], actions: 2, next state: ((4, 10), (3, 11)), reward: -6
step: 29, state: ((4, 10), (3, 11)), Q: [  -70.7894249    -72.76818089 -1006.9999925    -61.0646124 ], actions: 4, next state: ((4, 11), (3, 11)), reward: -5
step: 30, state: ((4, 11), (3, 11)), Q: [  -56.63092162   -66.45382147   -66.45394814 -1005.96929932], actions: 1, next state: ((3, 11), (2, 11)), reward: -6
step: 31, state: ((3, 11), (2, 11)), Q: [  -51.14234507   -63.06056758   -63.0633554  -1006.9961586 ], actions: 1, next state: ((2, 11), (1, 11)), reward: -7
step: 32, state: ((2, 11), (1, 11)), Q: [  -51.14234504   -58.61758842   -44.58822734 -1007.99951935], actions: 3, next state: ((2, 10), (1, 11)), reward: -8
step: 33, state: ((2, 10), (1, 11)), Q: [  -36.95780539   -53.14221534 -1008.98460388   -51.13736487], actions: 1, next state: ((1, 10), (1, 11)), reward: -7
step: 34, state: ((1, 10), (1, 11)), Q: [  -44.58753553   -44.58675184 -1007.99951935   -30.26040949], actions: 4, next state: ((1, 11), (1, 12)), reward: -6
step: 35, state: ((1, 11), (1, 12)), Q: [-36.94902605 -36.95771949 -36.95344776 -24.50546413], actions: 4, next state: ((1, 12), (1, 13)), reward: -5
step: 36, state: ((1, 12), (1, 13)), Q: [  -19.70248902 -1005.93859863   -30.16801806   -24.50546179], actions: 1, next state: ((0, 12), (1, 13)), reward: -6
step: 37, state: ((0, 12), (1, 13)), Q: [-19.70248439 -24.50493394 -26.50544751 -13.840898  ], actions: 4, next state: ((0, 13), (1, 13)), reward: -5
step: 38, state: ((0, 13), (1, 13)), Q: [-13.84042002  -8.9302     -19.7024844  -13.84088306], actions: 2, next state: ((1, 13), (2, 13)), reward: -4
step: 39, state: ((1, 13), (2, 13)), Q: [-13.83393253  -4.98       -13.84068923  -8.92983865], actions: 2, next state: ((2, 13), (3, 13)), reward: -3
step: 40, state: ((2, 13), (3, 13)), Q: [   -8.92926776    -2.         -1003.99617004    -4.97999953], actions: 2, next state: ((3, 13), (4, 13)), reward: -2

rewards: -388
print the historical actions: [[4], [1], [1], [1], [3], [1], [4], [4], [4], [4], [1], [4], [2], [2], [2], [3], [2], [4], [4], [4], [2], [4], [1], [3], [1], [4], [4], [4], [2], [4], [1], [1], [3], [1], [4], [4], [1], [4], [2], [2], [2]]
